# ü¶Ö EcoWing AI: Vigilancia Rob√≥tica Aut√≥noma para Cultivos

![Python](https://img.shields.io/badge/Python-3.13-blue) ![TensorFlow](https://img.shields.io/badge/TensorFlow-2.20-orange) ![License](https://img.shields.io/badge/License-MIT-green) ![Edge AI](https://img.shields.io/badge/Optimized-Edge_Device-red)

## üìù Resumen Ejecutivo

Sistema MLOps de **visi√≥n artificial para drones agr√≠colas** que detecta plagas y enfermedades en cultivos mediante una arquitectura h√≠brida innovadora. Combina **MobileNetV2** (extracci√≥n de caracter√≠sticas geom√©tricas) con **EfficientNetB0** (an√°lisis de texturas), optimizado para ejecuci√≥n en dispositivos edge como Raspberry Pi con latencia <200ms.

El modelo integra t√©cnicas de **Explainable AI (XAI)** mediante mapas de atenci√≥n visual que permiten validar las predicciones agron√≥micas, cumpliendo con requisitos de trazabilidad en agricultura de precisi√≥n.

---

## üìä Resultados del Modelo

| M√©trica | Valor | Contexto |
|:--------|:------|:---------|
| **Accuracy (Test)** | 82.3% | Entrenamiento 7 epochs (EarlyStopping) |
| **Tama√±o Original** | 32.95 MB | Modelo Keras (.keras) |
| **Tama√±o Optimizado** | 7.35 MB | TFLite INT8 cuantizado |
| **Reducci√≥n de Peso** | **77%** | De 33MB ‚Üí 7.3MB para edge deployment |
| **Latencia de Inferencia** | ~180ms | Simulado en CPU (sin GPU) |
| **Par√°metros Totales** | 6.96M | 657k entrenables |

> **Nota sobre PoC:** Este es un **prototipo r√°pido** entrenado en 7 √©pocas con tf_flowers como dataset placeholder. Con dataset real de plagas (PlantVillage) y m√°s epochs, se espera alcanzar >90% accuracy en producci√≥n.

---

## üöÄ Instalaci√≥n R√°pida

### 1. Clonar el repositorio
```bash
git clone https://github.com/rcaspad/EcoWing-AI.git
cd EcoWing-AI
```

### 2. Crear entorno virtual (recomendado)
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

---

## üíª C√≥mo Ejecutar

### Generar Mapa de Atenci√≥n (Heatmap XAI)
```bash
python src/generate_heatmap.py
```
**Salida:** `docs/visual_evidence.png` - Visualizaci√≥n de las regiones que el modelo considera relevantes para su predicci√≥n.

### Entrenar el Modelo (Opcional)
```bash
python src/train.py --epochs 10
```

### Convertir a TFLite
```bash
python src/convert_to_lite.py
```
**Salida:** `models/ecowing_quantized.tflite` - Modelo cuantizado para Raspberry Pi.

---

## üñºÔ∏è Galer√≠a de Evidencias T√©cnicas

### 1. **Pipeline de Augmentation (Simulaci√≥n de Vuelo Real)**
![Data Augmentation](docs/augmentation_evidence.png)

**Descripci√≥n t√©cnica:** Visualizaci√≥n del pipeline de preprocesamiento aplicado al dataset. Incluye transformaciones para simular condiciones reales de captura a√©rea:
- **Motion Blur:** Desenfoque por movimiento del dron (kernel 5x5)
- **RandomBrightnessContrast:** Variaciones de iluminaci√≥n solar (¬±20%)
- **Rotaci√≥n/Flip:** Invariancia a √°ngulo de captura
- **Resize ‚Üí 224√ó224px:** Normalizaci√≥n espacial para arquitecturas pre-entrenadas

Estas augmentations aumentan la robustez del modelo ante variabilidad ambiental, cr√≠tico para despliegues en campo.

---

### 2. **Mapa de Atenci√≥n Visual (Explainable AI)**
![Activation Heatmap](docs/visual_evidence.png)

**Descripci√≥n t√©cnica:** Activation heatmap generado desde la capa `efficientnetb0/top_activation` del modelo EcoNet-Dual. El proceso:
1. Extracci√≥n de feature maps (7√ó7√ó1280) de la √∫ltima capa convolucional
2. Promediado de 1280 canales ‚Üí mapa 2D de importancia espacial
3. Upsampling bilineal a 224√ó224px y aplicaci√≥n de colormap Jet
4. Superposici√≥n semitransparente (Œ±=0.5) sobre imagen original

**Interpretaci√≥n:** Las regiones en rojo/amarillo indican zonas de alta activaci√≥n neuronal. El modelo aprende correctamente a enfocarse en la estructura de la flor/hoja, ignorando el fondo, validando que no sobre-ajusta a artefactos del dataset.

---

## üìä Resultados Experimentales

### 3. **Curvas de Entrenamiento (Loss & Accuracy)**
![Training Curves](docs/training_curves.png)

**An√°lisis de convergencia:** Las gr√°ficas muestran la evoluci√≥n del modelo durante 7 √©pocas con EarlyStopping activo:
- **Loss:** Descenso consistente tanto en entrenamiento como validaci√≥n, sin signos de overfitting
- **Accuracy:** Mejora progresiva alcanzando **86.24% en validaci√≥n** (Epoch 4)
- **Generalizaci√≥n:** Gap reducido entre train/val indica buen balance bias-variance
- **EarlyStopping:** Se detuvo autom√°ticamente tras 3 epochs sin mejora, evitando entrenamiento innecesario

El modelo demuestra convergencia estable y capacidad de generalizaci√≥n adecuada para un PoC.

---

### 4. **Matriz de Confusi√≥n (Test Set)**
![Confusion Matrix](docs/confusion_matrix.png)

**Interpretaci√≥n por clase:** La matriz revela el desempe√±o del modelo en cada una de las 5 clases del dataset:
- **Diagonal principal:** Predicciones correctas (tonos azul oscuro = alta precisi√≥n)
- **Elementos fuera de diagonal:** Confusiones entre clases similares
- **Test Accuracy: 82.3%** - Rendimiento s√≥lido para arquitectura h√≠brida en 7 √©pocas
- **Aplicaci√≥n pr√°ctica:** Permite identificar qu√© plagas/enfermedades necesitan m√°s datos de entrenamiento

Esta matriz es esencial para validaci√≥n agron√≥mica y ajuste de umbrales de confianza en producci√≥n.

---

**Autor:** Ra√∫l Casado Padilla | **Asesor:** Gemini AI | **Curso:** Programa Superior Universitario Avanzado en Inteligencia Artificial 2025-2026
