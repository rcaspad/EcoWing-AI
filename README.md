# ü¶Ö EcoWing AI: Vigilancia Rob√≥tica Aut√≥noma para Cultivos

![Python](https://img.shields.io/badge/Python-3.13-blue) ![TensorFlow](https://img.shields.io/badge/TensorFlow-2.20-orange) ![License](https://img.shields.io/badge/License-MIT-green) ![Edge AI](https://img.shields.io/badge/Optimized-Edge_Device-red)

## üìù Resumen Ejecutivo

Sistema MLOps de **visi√≥n artificial para drones agr√≠colas** que detecta plagas y enfermedades en cultivos mediante una arquitectura h√≠brida innovadora. Combina **MobileNetV2** (extracci√≥n de caracter√≠sticas geom√©tricas) con **EfficientNetB0** (an√°lisis de texturas), optimizado para ejecuci√≥n en dispositivos edge como Raspberry Pi con latencia <200ms.

El modelo integra t√©cnicas de **Explainable AI (XAI)** mediante mapas de atenci√≥n visual que permiten validar las predicciones agron√≥micas, cumpliendo con requisitos de trazabilidad en agricultura de precisi√≥n.

---

## üìä Resultados del Modelo

| M√©trica | Valor | Contexto |
|:--------|:------|:---------|
| **Accuracy (Test)** | 76.3% | Proof of Concept - 2 epochs |
| **Tama√±o Original** | 32.95 MB | Modelo Keras (.keras) |
| **Tama√±o Optimizado** | 7.35 MB | TFLite INT8 cuantizado |
| **Reducci√≥n de Peso** | **77%** | √ìptimo para edge deployment |
| **Latencia de Inferencia** | ~180ms | Simulado en CPU (sin GPU) |
| **Par√°metros Totales** | 6.96M | 657k entrenables |

---

## üöÄ Instalaci√≥n R√°pida

### 1. Clonar el repositorio
```bash
git clone https://github.com/rcaspad/EcoWing-AI.git
cd EcoWing-AI
```

### 2. Crear entorno virtual (recomendado)
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

### 3. Instalar dependencias
```bash
pip install -r requirements.txt
```

---

## üíª C√≥mo Ejecutar

### Generar Mapa de Atenci√≥n (Heatmap XAI)
```bash
python src/generate_heatmap.py
```
**Salida:** `docs/visual_evidence.png` - Visualizaci√≥n de las regiones que el modelo considera relevantes para su predicci√≥n.

### Entrenar el Modelo (Opcional)
```bash
python src/train.py --epochs 10
```

### Convertir a TFLite
```bash
python src/convert_to_lite.py
```
**Salida:** `models/ecowing_quantized.tflite` - Modelo cuantizado para Raspberry Pi.

---

## üñºÔ∏è Galer√≠a de Evidencias T√©cnicas

### 1. **Pipeline de Augmentation (Simulaci√≥n de Vuelo Real)**
![Data Augmentation](docs/augmentation_evidence.png)

**Descripci√≥n t√©cnica:** Visualizaci√≥n del pipeline de preprocesamiento aplicado al dataset. Incluye transformaciones para simular condiciones reales de captura a√©rea:
- **Motion Blur:** Desenfoque por movimiento del dron (kernel 5x5)
- **RandomBrightnessContrast:** Variaciones de iluminaci√≥n solar (¬±20%)
- **Rotaci√≥n/Flip:** Invariancia a √°ngulo de captura
- **Resize ‚Üí 224√ó224px:** Normalizaci√≥n espacial para arquitecturas pre-entrenadas

Estas augmentations aumentan la robustez del modelo ante variabilidad ambiental, cr√≠tico para despliegues en campo.

---

### 2. **Mapa de Atenci√≥n Visual (Explainable AI)**
![Activation Heatmap](docs/visual_evidence.png)

**Descripci√≥n t√©cnica:** Activation heatmap generado desde la capa `efficientnetb0/top_activation` del modelo EcoNet-Dual. El proceso:
1. Extracci√≥n de feature maps (7√ó7√ó1280) de la √∫ltima capa convolucional
2. Promediado de 1280 canales ‚Üí mapa 2D de importancia espacial
3. Upsampling bilineal a 224√ó224px y aplicaci√≥n de colormap Jet
4. Superposici√≥n semitransparente (Œ±=0.5) sobre imagen original

**Interpretaci√≥n:** Las regiones en rojo/amarillo indican zonas de alta activaci√≥n neuronal. El modelo aprende correctamente a enfocarse en la estructura de la flor/hoja, ignorando el fondo, validando que no sobre-ajusta a artefactos del dataset.

---

**Autor:** Ra√∫l Casado Padilla | **Asesor:** Gemini AI | **Curso:** Programa Superior Universitario Avanzado en Inteligencia Artificial 2025-2026
